# DQL_cartpole

# 왜 시작했을까?
- 추천시스템에서 현재 각광받고 있는 알고리즘은 강화학습(Reinforcement Learning; RL)과 그래프 네트워크(Graph Neural Network;GNN)이다. 개인적으로 모두 처음 들어보는 알고리즘이어서, 관련 페이퍼를 읽어보았다. 강화학습의 경우, 어느정도 통계학 기반으로 진행되어서 쉽게 읽을 수 있었고, GNN의 경우에는 수리적 기반 지식이 부족해서 완전하게 이해하지 못했다. 또, 강화학습은 first paper가 짧기도 하고, 검색을 통해서 논문을 완전히 이해하였지만, GNN은 first paper가 30페이지였나? 그정도여서 읽을 엄두가 안났다. 그래서 기본적으로 알고 있던 CNN과 결합된 GCN논문부터 읽는게 수월할 거라고 생각했는데, 이러한 생각이 아주 큰 오산이었다. GCN에서 나오는 GNN 알고리즘 설명 부분이 매우 많이 생략되어 있었고, 오히려 한번도 배워본 적이 없었던 XAI, 설명가능한 인공지능과 결합된 GNNeXplainer 페이퍼에서 기본적인 GNN 구조를 이해할 수 있었다. 어쨌든 그렇게 강화학습 첫번째 페이퍼를 읽으면서 강화학습에 대한 이론적인 기반을 배웠고, 딥러닝과 결합되면서 아주 우수한 성능을 갖는 DQN 알고리즘을 알게 되었다. 아마 추천시스템에서 각광받고 있는 것도 이 때문인것 같다. 딥러닝과 강화학습이 결합되면서, 추천시스템이라는 새로운 분야에서 각광받는 것 같다. 따라서, 강화학습을 이론적인 배경에서만 이해하는 것이 아니라, 실제 코드로 구현해보면서 이해도를 높이고 싶었다. 그래서 이런 생각을 가지고 있다가 기분이 안좋아서 일을 벌려야 했을때, 시작해보았다.

- 하지만, 문제가 생겼다. 추천 시스템과 관련한 데이터가 나에게는 없었고, 크롤링까지도 생각해보았지만, 다른 일도 갑자기 많이 생겨서 그렇게까지 하지는 못했다. 그래서 우선은 강화학습이 많이 사용되는 게임 분야(Cartpole)의 코드들만 구현해보았고, baseline과 DQN 모두 구현해보았다!

## What is Cartpole?
![image](https://jonghyunho.github.io/assets/img/posts/20200505/cartpole_episode_100.gif)

